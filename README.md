<h2>Data Pipeline using AWS&Python </h2>
<h3>Introduction & Goals</h3>
     <br>The purpose of this project is to build a pipeline that will process the selected ecommerce dataset using AWS services&Python and prepare the data for further analysis</br>
     <br>Expected Results:</br>
     <br>1.Access to Customer & Invoice data through API</br>
     <br>2.Data Analysis -Maximum priced product country-wise,total sales amount per month countrywise<br/>
 <h3>Contents</h3>
 
 <br>[1.Dataset](https://www.google.com)</br>
 <br>[2.Process](https://www.google.com)</br>
 <br>[3.Data Analysis](https://www.google.com)</br>
 <h3>1.Dataset</h3>
     The dataset used here is an ecommerce data with the following attributes,sourced from kaggle<link>
 
 <h3>2.Process</h3>
 
![alt text](https://github.com/shruthi2611/DEProjects/blob/main/process.png "Process flow")
 
 <br>[1.Simulation of streaming](https://github.com/shruthi2611/DEProjects/blob/main/simulation_src_code.ipynb)</br>  
     
 <br>[2.Data ingestion from source to kinesis via API](https://github.com/shruthi2611/DEProjects/blob/main/Write_to_kinesis.py)</br>

<br>[3.Storing unprocessed data in S3](https://github.com/shruthi2611/DEProjects/blob/main/write_kinesis_to_s3.py)</br>
     
 <br>[4.Writing data to DynamoDB](https://github.com/shruthi2611/DEProjects/blob/main/Kinesis_to_Dynamodb.py)</br>
     
 <br>[5.Creating delivery stream in Kinesis Firehose](https://www.google.com)</br>
     
 <br>[6.Processing from firehose to Redshift](https://www.google.com)</br>
    
  <h3>3.Data Analysis</h3>
   
     
     

